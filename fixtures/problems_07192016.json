[{"model": "wordclouds.problem", "pk": 1, "fields": {"turk_id": "0IZCE0iqHL", "paper_id": null, "abstract": "Metasurfaces utilizing engineered metallic nanostructures have recently emerged as an important means to manipulate the propagation of light waves in a prescribed manner. However, conventional metallic metasurfaces mainly efficiently work in the visible and near-infrared regime, and lack sufficient tunability. In this work, combining the pronounced plasmonic resonance of patterned graphene structures with a subwavelength-thick optical cavity, we propose and demonstrate novel graphene metasurfaces that manifest the potential to dynamically control the phase and amplitude of infrared light with very high efficiency. It is shown that the phase of the infrared light reflected from a simple graphene ribbon metasurface can span over almost the entire 2 range by changing the width of the graphene ribbons, while the amplitude of the reflection can be maintained at high values without significant variations. We successfully realize anomalous reflection, reflective focusing lenses, and non-diffracting Airy beams based on graphene metasurfaces. Our results open up a new paradigm of highly integrated photonic platforms for dynamic beam shaping and adaptive optics in the crucial infrared wavelength range.", "desc": "dynamically control the phase and amplitude of infrared light with very high efficiency", "user": null, "trial": null, "type": "make", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 2, "fields": {"turk_id": "0c3xFNeP5P", "paper_id": null, "abstract": "The valuation of the real option to store liquefied natural gas (LNG) at the downstream terminal of an LNG value chain is an important problem in practice. As the exact valuation of this real option is computationally intractable, we develop a novel and tractable heuristic model for its strategic valuation that integrates models of LNG shipping, natural gas price evolution, and inventory control and sale into the wholesale natural gas market. We incorporate real and estimated data to quantify the value of this real option and its dependence on the throughput of an LNG chain, the type of price variability, the type of inventory control policy employed, and the level of stochastic variability in both the shipping model and the natural gas price model used. In addition, we develop an imperfect information dual upper bound to assess the effectiveness of our heuristic, and find that our method is highly accurate. Our approach also has potential relevance to value the real option to store other commodities in facilities located downstream from a commodity production or transportation stage, such as petroleum and agricultural products, chemicals, and metals, or the real option to store the input used in the production of a commodity, such as electricity.", "desc": "valuation of liquefied natural gas storage options", "user": null, "trial": null, "type": "make", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 3, "fields": {"turk_id": "1ewbCznf4F", "paper_id": null, "abstract": "History event related knowledge is precious and imagery is a powerful medium that records diverse information about the event. In this paper, we propose to automatically construct an image profile given a one sentence description of the historic event which contains where, when, who and what elements. Such a simple input requirement makes our solution easy to scale up and support a wide range of culture preservation and curation related applications ranging from wikipedia enrichment to history education. However, history relevant information on the web is available as \"wild and dirty\" data, which is quite different from clean, manually curated and structured information sources. There are two major challenges to build our proposed image profiles: 1) unconstrained image genre diversity. We categorize images into genres of documents/maps, paintings or photos. Image genre classification involves a full-spectrum of features from low-level color to high-level semantic concepts. 2) image content diversity. It can include faces, objects and scenes. Furthermore, even within the same event, the views and subjects of images are diverse and correspond to different facets of the event. To solve this challenge, we group images at two levels of granularity: iconic image grouping and facet image grouping. These require different types of features and analysis from near exact matching to soft semantic similarity. We develop a full-range feature analysis module which is composed of several levels, each suitable for different types of image analysis tasks. The wide range of features are based on both classical hand-crafted features and different layers of a convolutional neural network. We compare and study the performance of the different levels in the full-range features and show their effectiveness on handling such a wild, unconstrained dataset.", "desc": "automatically construct an image profile given a one sentence description of the historic event which contains where, when, who and what elements", "user": null, "trial": null, "type": "make", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 4, "fields": {"turk_id": "1p63yA50ad", "paper_id": null, "abstract": "We describe a method to extract tabular data from web pages. Rather than just analyzing the DOM tree, we also exploit visual cues in the rendered version of the document to extract data from tables which are not explicitly marked with an HTML table element. To detect tables, we rely on a variant of the well-known X-Y cut algorithm as used in the OCR community. We implemented the system by directly accessing Mozillas box model that contains the positional data for all HTML elements of a given web page.", "desc": "extracting tabular data from web pages", "user": null, "trial": null, "type": "make", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 5, "fields": {"turk_id": "25qYNuAljG", "paper_id": null, "abstract": "Shared information displays are increasingly present in built environments. Terminal displays in airports show arrival and departure information, monitors in hotels and convention centers show room assignments, and whiteboards in hospitals show schedules and help staff know what others are doing. One of the most important types of displays is the schedule board for surgical suites. Surgical suites are a highly dynamic setting, where doctors, nurses, equipment, rooms, and patients must be perfectly coordinated. Schedule changes occur frequently and must be shared among staff. This research examines the design of hospital architecture (placement of walls, corridors, furnishings) and information artifacts for more effective information sharing and coordination of surgeries. I conducted field studies in four hospital surgical suites and a survey of surgical suite directors nationwide. I describe factors of the architecture, and information available around surgical suite schedule displays that are associated with information sharing and coordination outcomes. From the field studies, I developed the concept of an information hotspot  a place where people congregate to receive and provide information, public displays offer up-to-date information, and coordination workers answer questions, resolve conflicts, and keep information up-to-date. The information hotspot concept guided my design research. I developed design principles for the placement of schedule boards and control desks; design guidelines for the location of surgical suite displays and control desks; an evaluation list for surgical suites; and a three-tiered design intervention strategy ranging in implementation effort. In a follow-up national survey of surgical suite directors, I studied linkages between surgical suite architecture, information artifacts and communication practices, workplace characteristics, information sharing, and coordination speed and stress. I found that visibility between the schedule board and control desk in the surgical suite, traffic-free areas around the schedule board, and complete, up-to-date schedule board information were related to information sharing and coordination outcomes.", "desc": "Effective information sharing and coordination of surgeries.", "user": null, "trial": null, "type": "understand + make", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 6, "fields": {"turk_id": "29anwl7KZ1", "paper_id": null, "abstract": "Successful object recognition is essential for finding food, identifying kin, and avoiding danger, as well as many other adaptive behaviors. To accomplish this feat, the visual system must reconstruct 3-D interpretations from 2-D snapshots falling on the retina. Theories of recognition address this process by focusing on the question of how object representations are encoded with respect to viewpoint. Although empirical evidence has been equivocal on this question, a growing body of surprising results, including those obtained in the experiments presented in this case study, indicates that recognition is often viewpoint dependent. Such findings reveal a prominent role for viewpointdependent mechanisms and provide support for the multiple-views approach, in which objects are encoded as a set of view-specific representations that are matched to percepts using normalization procedures.", "desc": "Reconstruct 3-D interpretations from 2-D snapshots falling on the retina.", "user": null, "trial": null, "type": "understand", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 7, "fields": {"turk_id": "44SWnb2Pwl", "paper_id": null, "abstract": "This paper presents a new method for fabricating soft and stretchable liquid-phase microelectronics that feature circuit elements with micron-scale line width. In contrast to conventional microelectronics, these circuits are composed of a soft elastomer embedded with microfl uidic channels fi lled with eutectic Gallium-Indium (EGaIn) metal alloy. The EGaIn traces are liquid at room temperature and therefore remain intact and electrically functional as the surrounding elastomer elastically deforms during stretching and bending. The fabrication method uses emerging techniques in soft lithography. Microchannels are molded on to the surface of poly(dimethylsiloxane) (PDMS) elastomer and fi lled with EGaIn using a micro-transfer deposition step that exploits the unique wetting properties of EGaIn in air. After sealing with an addition layer of PDMS, the liquid-fi lled channels function as stretchable circuit wires or capacitor electrodes. The presented approach allows for the creation of micron-scale circuit features with a line width (2 m) and spacing (1 m) that is an order-of-magnitude smaller than those previously demonstrated.", "desc": "fabricating soft and stretchable liquid-phase microelectronics", "user": null, "trial": null, "type": "make", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 8, "fields": {"turk_id": "7TZT6eSk2C", "paper_id": null, "abstract": "We present MindMiner, a mixed-initiative interface for capturing subjective similarity measurements via a combination of new interaction techniques and machine learning algorithms. MindMiner collects qualitative, hard to express similarity measurements from users via active polling with uncertainty and example based visual constraint creation. MindMiner also formulates human prior knowledge into a set of inequalities and learns a quantitative similarity distance metric via convex optimization. In a 12-participant peer-review understanding task, we found MindMiner was easy to learn and use, and could capture users' implicit knowledge about writing performance and cluster target entities into groups that match subjects' mental models.", "desc": "collect qualitative, hard to express similarity measurements from users", "user": null, "trial": null, "type": "make", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 9, "fields": {"turk_id": "8nyAgdlaZ3", "paper_id": null, "abstract": "We show that nanowire field-effect transistor (NWFET) arrays fabricated on both planar and flexible polymeric substrates can be reproducibly interfaced with spontaneously-beating embryonic chicken hearts in both planar and bent conformations. Simultaneous recordings from glass microelectrode and NWFET devices show that NWFET conductance variations are synchronized with the beating heart. The conductance change associated with beating can be tuned substantially by device sensitivity, although the voltage-calibrated signals, 46 mV, are relatively constant and typically larger than signals recorded by microelectrode arrays. Multiplexed recording from NWFET arrays yielded signal propagation times across the myocardium with high spatial resolution. The transparent and flexible NWFET chips also enable simultaneous electrical recording and optical registration of devices to heart surfaces in three-dimensional conformations not possible with planar microdevices. The capability of simultaneous optical imaging and electrical recording also could be used to register devices to a specific region of the myocardium at the cellular level, and more generally, NWFET arrays fabricated on increasingly flexible plastic and/or biopolymer substrates have the potential to become unique tools for electrical recording from other tissue/organ samples or as powerful implants.", "desc": "reproducibly interface nanowire field-effect transistor arrays with spontaneously-beating embyronic chicken hearts", "user": null, "trial": null, "type": "make", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 10, "fields": {"turk_id": "DJ2ADGD5es", "paper_id": null, "abstract": "We present two projects that facilitate collective music creativity over networks. One system is a participative social music system on mobile devices. The other is a collaborative music mixing environment that adheres to the Creative Commons license [1]. We discuss how network and community infrastructures affect the creative musical process, and the implications for artists creating new content for these formats. The projects described are real-world examples of collaborative systems as musical works.", "desc": "facilitate collective music creativity over networks", "user": null, "trial": null, "type": "make", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 11, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "How effective are call and SMS logs in modeling tie strength? Frequency and duration of communication has long been cited as a major aspect of tie strength. Intuitively, this makes sense: people communicate with those that they feel close to. Highly cited research papers have pushed this idea further, using communication as a direct proxy for tie strength. However, this operationalization has not been validated. Our work evaluates this assumption. We collected call and SMS logs and ground truth relationship data from 36 participants. Consistent with theory, we found that frequent or long-duration communication likely indicates a strong tie. However, the use of call and SMS logs produced many errors in separating strong and weak ties, suggesting this approach is incomplete. Follow-up interviews indicate fundamental challenges for inferring tie strength from communication logs.", "desc": "measure importance of call and SMS logs in modeling tie strength", "user": null, "trial": null, "type": "only findings", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 12, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "We study the segmental recurrent neural network for end-to-end acoustic modelling. This model connects the segmental conditional random field (CRF) with a recurrent neural network (RNN) used for feature extraction. Compared to most previous CRF-based acoustic models, it does not rely on an external system to provide features or segmentation boundaries. Instead, this model marginalises out all the possible segmentations, and features are extracted from the RNN trained together with the segmental CRF. In essence, this model is self-contained and can be trained end-to-end. In this paper, we discuss practical training and decoding issues as well as the method to speed up the training in the context of speech recognition. We performed experiments on the TIMIT dataset. We achieved 17.3 phone error rate (PER) from the first-pass decoding --- the best reported result using CRFs, despite the fact that we only used a zeroth-order CRF and without using any language model.", "desc": "transcribe speech with end-to-end acoustic modelling", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 13, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Open Display Networks have the potential to allow many content creators to publish their media to an open-ended set of screen displays. However, this raises the issue of how to match that content to the right displays. In this study, we aim to understand how the perceived utility of particular media sharing scenarios is affected by three independent variables, more specifically: (a) the locativeness of the content being shared; (b) how personal that content is and (c) the scope in which it is being shared. To assess these effects, we composed a set of 24 media sharing scenarios embedded with different treatments of our three independent variables. We then asked 100 participants to express their perception of the relevance of those scenarios. The results suggest a clear preference for scenarios where content is both local and directly related to the person that is publishing it. This is in stark contrast to the types of content that are commonly found in public displays, and confirms the opportunity that open displays networks may represent a new media for self-expression. This novel understanding may inform the design of new publication paradigms that will enable people to share media across the display networks.", "desc": "How do locativeness, persnal-ness, and scope affect percieved utility of media?", "user": null, "trial": null, "type": "only findings", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 14, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "We introduce recurrent neural network grammars, probabilistic models of sentences with explicit phrase structure. We explain efficient inference procedures that allow application to both parsing and language modeling. Experiments show that they provide better parsing in English than any single previously published supervised generative model and better language modeling than state-of-the-art sequential RNNs in English and Chinese.", "desc": "parse language", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 15, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "The idea of using a data-driven phoneme confusion matrix (PCM) to enhance speech recognition and retrieval performance is not new to the speech community. Although empirical results show various degrees of improvements brought by introducing a PCM, the underlying data-driven processes introduced in most papers are rather ad-hoc and lack rigorous statistical justifications. In this paper we will focus on the statistical aspects of PCM generation, propose and justify a novel expectation-maximization based algorithm for data-driven PCM generation. We will evaluate the performance of the generated PCMs under the context of low-resource spoken term detection, with primary focus on out-of-vocabulary keywords.", "desc": "transcribe speech using a data-driven phoneme confusion matrix (PCM)", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 16, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "We present MindMiner, a mixed-initiative interface for capturing subjective similarity measurements via a combination of new interaction techniques and machine learning algorithms. MindMiner collects qualitative, hard to express similarity measurements from users via active polling with uncertainty and example based visual constraint creation. MindMiner also formulates human prior knowledge into a set of inequalities and learns a quantitative similarity distance metric via convex optimization. In a 12-subject peer-review understanding task, we found MindMiner was easy to learn and use, and could capture users\u2030\u0170\u015e implicit knowledge about writing performance and cluster target entities into groups that match subjects\u2030\u0170\u015e mental models. We also found that MindMiner\u2030\u0170\u015es constraint suggestions and uncertainty polling functions could improve both efficiency and the quality of clustering.", "desc": "capture subjective similarity measurements", "user": null, "trial": null, "type": "similar to above", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 17, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Rapid feedback is a core component of mastery learning, but feedback on open-ended work requires days or weeks in most classes today. This paper introduces PeerStudio, an assessment platform that leverages the large number of students' peers in online classes to enable rapid feedback on in-progress work. Students submit their draft, give rubric-based feedback on two peers' drafts, and then receive peer feedback. Students can integrate the feedback and repeat this process as often as they desire. In MOOC deployments, the median student received feedback in just twenty minutes. Rapid feedback on in-progress work improves course outcomes: in a controlled experiment, students' final grades improved when feedback was delivered quickly, but not if delayed by 24 hours. More than 3,600 students have used PeerStudio in eight classes, both massive and in-person. This research demonstrates how large classes can leverage their scale to encourage mastery through rapid feedback and revision.", "desc": "give students feedback for works in progress rapidly", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 18, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Automatic real-time captioning provides immediate and on demand access to spoken content in lectures or talks, and is a crucial accommodation for deaf and hard of hearing (DHH) people. However, in the presence of specialized content, like in technical talks, automatic speech recognition (ASR) still makes mistakes which may render the output incomprehensible. In this paper, we introduce a new approach, which allows audience or crowd workers, to quickly correct errors that they spot in ASR output. Prior approaches required the crowd worker to manually \u2030\u0170\u010eedit\u2030\u0170\u0165 the ASR hypothesis by selecting and replacing the text, which is not suitable for real-time scenarios. Our approach is faster and allows the worker to simply type corrections for misrecognized words as soon as he or she spots them. The system then finds the most likely position for the correction in the ASR output using keyword search (KWS) and stitches the word into the ASR output. Our work demonstrates the potential of computation to incorporate human input quickly enough to be usable in real-time scenarios, and may be a better method for providing this vital accommodation to DHH people.", "desc": "transcribe speech in real time when technical vocabulary must be accurately captured", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 19, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "We present MindMiner, a mixed-initiative interface for capturing subjective similarity measurements via a combination of new interaction techniques and machine learning algorithms. MindMiner collects qualitative, hard to express similarity measurements from users via active polling with uncertainty and example based visual constraint creation. MindMiner also formulates human prior knowledge into a set of inequalities and learns a quantitative similarity distance metric via convex optimization. In a 12-participant peer-review understanding task, we found MindMiner was easy to learn and use, and could capture users' implicit knowledge about writing performance and cluster target entities into groups that match subjects' mental models.", "desc": "capture subjective similarity measurements", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 20, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Many people use the Internet every day yet know little about how it really works. Prior literature diverges on how people\u2030\u0170\u015es Internet knowledge affects their privacy and security decisions. We undertook a qualitative study to understand what people do and do not know about the Internet and how that knowledge affects their responses to privacy and security risks. Lay people, as compared to those with computer science or related backgrounds, had simpler mental models that omitted Internet levels, organizations, and entities. People with more articulated technical models perceived more privacy threats, possibly driven by their more accurate understanding of where specific risks could occur in the network. Despite these differences, we did not find a direct relationship between people\u2030\u0170\u015es technical background and the actions they took to control their privacy or increase their security online. Consistent with other work on user knowledge and experience, our study suggests a greater emphasis on policies and systems that protect privacy and security without relying too much on users\u2030\u0170\u015e security practices.", "desc": "How do people's understanding of the internet affect their online security practices?", "user": null, "trial": null, "type": "moslty findings", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 21, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Telepresence means business people can make deals in other countries, doctors can give remote medical advice, and soldiers can rescue someone from thousands of miles away. When interaction is mediated, people are removed from and lack context about the person they are making decisions about. In this paper, we explore the impact of technological mediation on risk and dehumanization in decision-making. We conducted a laboratory experiment involving medical treatment decisions. The results suggest that technological mediation influences decision making, but its influence depends on an individual's self-construal: participants who saw themselves as defined through their relationships (interdependent self-construal) recommended riskier and more painful treatments in video conferencing than when face-to-face. We discuss implications of our results for theory and future research.", "desc": "what is the impact of technological mediation on risk and dehumanization in decision-making", "user": null, "trial": null, "type": "only findings", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 22, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Social influence is key in technology adoption, but its role in security-feature adoption is unique and remains unclear. Here, we analyzed how three Facebook security features' Login Approvals, Login Notifications, and Trusted Contacts-diffused through the social networks of 1.5 million people. Our results suggest that social influence affects one's likelihood to adopt a security feature, but its effect varies based on the observability of the feature, the current feature adoption rate among a potential adopter's friends, and the number of distinct social circles from which those feature-adopting friends originate. Curiously, there may be a threshold higher than which having more security feature adopting friends predicts for higher adoption likelihood, but below which having more feature-adopting friends predicts for lower adoption likelihood. Furthermore, the magnitude of this threshold is modulated by the attributes of a feature-features that are more noticeable (Login Approvals, Trusted Contacts) have lower thresholds.", "desc": "How does social influence affect technology adoption?", "user": null, "trial": null, "type": "only findings", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 23, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Increasingly, the advice people receive on the Internet is socially transparent in the sense that it displays contextual information about the advice-givers or their actions. We hypothesize that activity transparency -seeing an advice giver's process while creating his or her recommendations - will increase advice taking. We report three experiments testing the effect of activity transparency on taking mediocre advice. We found that the presence of a web history increased the likelihood of following a financial advisor's advice and reduced participant earnings (Exp. 1), especially when the web history implied greater task focus (Exp. 2, 3). CSCW research usually emphasizes how to increase information sharing; this work suggests when shared information may be inappropriate. We suggest ways to counter activity transparency's potential downsides.", "desc": "How does transparency in advice-giving affect acceptance of advice?", "user": null, "trial": null, "type": "only findings", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 24, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "In a variety of peer production settings, from Wikipedia to open source software development to crowdsourcing, individuals may encounter, edit, or review the work of unknown others. Typically this is done without much context to the person's past behavior or performance. To understand how exposure to an unknown individual's activity history influences attitudes and behaviors, we conducted an online experiment on Mechanical Turk varying the content, quality, and presentation of information about another Turker's work history. Surprisingly, negative work history did not lead to negative outcomes, but in contrast, a positive work history led to positive initial impressions that persisted in the face of contrary information. This work provides insight into the impact of activity history design factors on psychological and behavioral outcomes that can be of use in other related settings.", "desc": "How does activity history design influence psychological and behavioral outcomes?", "user": null, "trial": null, "type": "only findings", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 25, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Software algorithms are changing how people work in an ever-growing number of fields, managing distributed human workers at a large scale. In these work settings, human jobs are assigned, optimized, and evaluated through algorithms and tracked data. We explore the impact of this algorithmic, data-driven management on human workers and work practices in the context of Uber and Lyft, new ridesharing services. Our findings from a qualitative study describe how drivers responded when algorithms assigned work, provided informational support, and evaluated their performance, and how drivers used online forums to socially make sense of the algorithm features. Implications and future work are discussed.", "desc": "How are software algorithms chaning the work place?", "user": null, "trial": null, "type": "only findings", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 26, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Large-scale content-based semantic search in video is an interesting and fundamental problem in multimedia analysis and retrieval. Existing methods index a video by the raw concept detection score that is dense and inconsistent, and thus cannot scale to \"big data\" that are readily available on the Internet. This paper proposes a scalable solution. The key is a novel step called concept adjustment that represents a video by a few salient and consistent concepts that can be efficiently indexed by the modified inverted index. The proposed adjustment model relies on a concise optimization framework with interpretations. The proposed index leverages the text-based inverted index for video retrieval. Experimental results validate the efficacy and the efficiency of the proposed method. The results show that our method can scale up the semantic search while maintaining state-of-the-art search performance. Specifically, the proposed method (with reranking) achieves the best result on the challenging TRECVID Multimedia Event Detection (MED) zero-example task. It only takes 0.2 second on a single CPU core to search a collection of 100 million Internet videos.", "desc": "search video with Large-scale content-based semantic search when scaliblility is an issue", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 27, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Websites can record individual users' activities and display them in a variety of ways. There is a tradeoff between detail and abstraction in visualization, especially when the amount of content increases and becomes more difficult to process. We conducted an experiment on Mechanical Turk varying the quality, detail, and visual presentation of information about an individual's past work to see how these design features affected perceptions of the worker. We found that providing detail in the display through text increased processing time and led to less positive evaluations. Visually abstract displays required less processing time but decreased confidence in evaluation. This suggests that different design parameters may engender differing psychological processes that influence reactions towards an unknown person.", "desc": "how do different design parameters (detail vs abstraction) about work history affect perceptions of the worker?", "user": null, "trial": null, "type": "only findings", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 28, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Anonymity online is important to people at times in their lives. Anonymous communication applications such as Whisper and YikYak enable people to communicate with strangers anonymously through their smartphones. We report results from semi-structured interviews with 18 users of these apps. The goal of our study was to identify why and how people use anonymous apps, their perceptions of their audience and interactions on the apps, and how these apps compare with other online social communities. We present a typology of the content people share, and their motivations for participation in anonymous apps. People share various types of content that range from deep confessions and secrets to lighthearted jokes and momentary feelings. An important driver for participation and posting is to get social validation from others, even though they are anonymous strangers. We also find that participants believe these anonymous apps allow more honesty, openness, and diversity of opinion than they can find elsewhere. Our results provide implications for how anonymity in mobile apps can encourage expressiveness and interaction among users.", "desc": "identify why and how people use anonymous apps, their perceptions of their audience and interactions on the apps", "user": null, "trial": null, "type": "only findings", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 29, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "As news reading becomes more social, how do different types of annotations affect people's selection of news articles? This paper reports on results from two experiments looking at social annotations in two different news reading contexts. The first experiment simulates a logged-out experience with annotations from strangers, a computer agent, and a branded company. Results indicate that, perhaps unsurprisingly, annotations by strangers have no persuasive effects. However, surprisingly, unknown branded companies still had a persuasive effect. The second experiment simulates a logged-in experience with annotations from friends, finding that friend annotations are both persuasive and improve user satisfaction over their article selections. In post-experiment interviews, we found that this increased satisfaction is due partly because of the context that annotations add. That is, friend annotations both help people decide what to read, and provide social context that improves engagement. Interviews also suggest subtle expertise effects. We discuss implications for design of social annotation systems and suggestions for future research.", "desc": "how do different types of annotations affect people's selection of news articles", "user": null, "trial": null, "type": "only findings", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 30, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "We present an approach for the detection of coordinate-term relationships between entities from the software domain, that refer to Java classes. Usually, relations are found by examining corpus statistics associated with text entities. In some technical domains, however, we have access to additional information about the real-world objects named by the entities, suggesting that coupling information about the \"grounded\" entities with corpus statistics might lead to improved methods for relation discovery. To this end, we develop a similarity measure for Java classes using distributional information about how they are used in software, which we combine with corpus statistics on the distribution of contexts in which the classes appear in text. Using our approach, cross-validation accuracy on this dataset can be improved dramatically, from around 60% to 88%. Human labeling results show that our classifier has an F1 score of 86% over the top 1000 predicted pairs.", "desc": "detect coordinate-term relationships between entities (java classes)", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 31, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "We introduce an algorithm for automatic selection of semantically-resonant colors to represent data (e.g., using blue for data about \u2030\u0170\u010eoceans\u2030\u0170\u0165, or pink for \u2030\u0170\u010elove\u2030\u0170\u0165). Given a set of categorical values and a target color palette, our algorithm matches each data value with a unique color. Values are mapped to colors by collecting representative images, analyzing image color distributions to determine value-color affinity scores, and choosing an optimal assignment. Our affinity score balances the probability of a color with how well it discriminates among data values. A controlled study shows that expert-chosen semantically-resonant colors improve speed on chart reading tasks compared to a standard palette, and that our algorithm selects colors that lead to similar gains. A second study verifies that our algorithm effectively selects colors across a variety of data categories.", "desc": "select semantically-resonant colors to represent data automatically", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 32, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "History event related knowledge is precious and imagery is a powerful medium that records diverse information about the event. In this paper, we propose to automatically construct an image profile given a one sentence description of the historic event which contains where, when, who and what elements. Such a simple input requirement makes our solution easy to scale up and support a wide range of culture preservation and curation related applications ranging from wikipedia enrichment to history education. However, history relevant information on the web is available as \"wild and dirty\" data, which is quite different from clean, manually curated and structured information sources. There are two major challenges to build our proposed image profiles: 1) unconstrained image genre diversity. We categorize images into genres of documents/maps, paintings or photos. Image genre classification involves a full-spectrum of features from low-level color to high-level semantic concepts. 2) image content diversity. It can include faces, objects and scenes. Furthermore, even within the same event, the views and subjects of images are diverse and correspond to different facets of the event. To solve this challenge, we group images at two levels of granularity: iconic image grouping and facet image grouping. These require different types of features and analysis from near exact matching to soft semantic similarity. We develop a full-range feature analysis module which is composed of several levels, each suitable for different types of image analysis tasks. The wide range of features are based on both classical hand-crafted features and different layers of a convolutional neural network. We compare and study the performance of the different levels in the full-range features and show their effectiveness on handling such a wild, unconstrained dataset.", "desc": "mine images in a scalable approach", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 33, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Distant labeling for information extraction (IE) suffers from noisy training data. We describe a way of reducing the noise associated with distant IE by identifying coupling constraints between potential instance labels. As one example of coupling, items in a list are likely to have the same label. A second example of coupling comes from analysis of document structure: in some corpora, sections can be identified such that items in the same section are likely to have the same label. Such sections do not exist in all corpora, but we show that augmenting a large corpus with coupling constraints from even a small, well-structured corpus can improve performance substantially, doubling F1 on one task.", "desc": "reduce the noise associated with distant information extraction", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 34, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Student discussions over video in massive classes allow students to explore course content, share personal experiences and get feedback on their ideas. However, such discussions frequently turn into casual conversations without focusing on the curriculum and the learning objectives. This short paper explores whether students can achieve multiple learning objectives by solving challenges collaboratively during discussions. We introduce `think-pair-share' technique for video discussions. Our pilot results, drawn from a Coursera class, suggest that participants prefer to exchange information with their peers using personal stories and connecting stories with curriculum increases participant engagement.", "desc": "solve challenges collaboratively during discussions to achieve multiple learning objectives", "user": null, "trial": null, "type": "only findings", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 35, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "This study explored the association between different types of brief disagreements and subsequent levels of expressed psychological uncertainty, a fundamental cognitive aspect of complex problem solving. We examined 11\u2030\u0170\u00e4hours (11\u2030\u0170\u00e4861 utterances) of conversations in expert science teams, sampled across the first 90\u2030\u0170\u00e4days of the Mars Exploration Rover mission. Utterances were independently coded for micro-conflicts and expressed psychological uncertainty. Using time-lagged hierarchical linear modeling applied to blocks of 25 utterances, we found that micro-conflicts regarding rover planning were followed by greater uncertainty. Brief disagreements about science issues were followed by an increase in expressed uncertainty early in the mission. Examining the potential reverse temporal association, uncertainty actually predicted fewer subsequent disagreements, ruling out indirect, third variable associations of conflict and uncertainty. Overall, these findings suggest that some forms of disagreement may serve to uncover important areas of uncertainty in complex teamwork, perhaps via revealing differences in mental models.Copyright \u013a\u00a9 2016 John Wiley & Sons, Ltd.", "desc": "association between different types of brief disagreements and subsequent levels of expressed psychological uncertainty", "user": null, "trial": null, "type": "only findings", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 36, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "In today's systems, restricting the authority of untrusted code is difficult because, by default, code has the same authority as the user running it. Object capabilities are a promising way to implement the principle of least authority, but being too low-level and fine-grained, take away many conveniences provided by module systems. We present a module system design that is capability-safe, yet preserves most of the convenience of conventional module systems. We demonstrate how to ensure key security and privacy properties of a program as a mode of use of our module system. Our authority safety result formally captures the role of mutable state in capability-based systems and uses a novel non-transitive notion of authority, which allows us to reason about authority restriction: the encapsulation of a stronger capability inside a weaker one.", "desc": "restrict the authority of untrusted code", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 37, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Low-cost genetic sequencing, coupled with novel social media platforms and visualization techniques, present a new frontier for scientific participation, whereby people can learn, share, and act on data embedded within their own bodies. Our study of 23andMe, a popular genetic testing service, reveals how users make sense of and contextualize their genetic results, critique and evaluate the underlying research, and reflect on the broader implications of genetic testing. We frame user groups as citizen science publicsgroups that coalesce around scientific issues and work towards resolving shared concerns. Our findings show that personal genetics serves as a site for public engagement with science, whereby communities of biological citizens creatively interpret, debate, and act on professional research. We conclude with design trajectories at the intersection of genetics and creativity support tools: platforms for aggregating hybrid knowledge; tools for creative reflection on professional science; and strategies for supporting collaborations across communities.", "desc": "How do users make sense of and contextualize their genetic results", "user": null, "trial": null, "type": "only discussion", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 38, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "We propose a hierarchical attention network for document classification. Our model has two distinctive characteristics: (i) it has a hierarchical structure that mirrors the hierarchical structure of documents; (ii) it has two levels of attention mechanisms applied at the word- and sentence-level, enabling it to attend differentially to more and less important con- tent when constructing the document representation. Experiments conducted on six large scale text classification tasks demonstrate that the proposed architecture outperform previous methods by a substantial margin. Visualization of the attention layers illustrates that the model selects qualitatively informative words and sentences.", "desc": "classify documents", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 39, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "In this paper, we define the problem of coreference resolution in text as one of clustering with pair- wise constraints where human experts are asked to provide pairwise constraints (pairwise judgments of coreferentiality) to guide the clustering process. Positing that these pairwise judgments are easy to obtain from humans given the right context, we show that with significantly lower number of pair- wise judgments and feature-engineering effort, we can achieve competitive coreference performance. Further, we describe an active learning strategy that minimizes the overall number of such pairwise judgments needed by asking the most informative questions to human experts at each step of coreference resolution. We evaluate this hypothesis and our algorithms on both entity and event coreference tasks and on two languages.", "desc": "resolve coreferences in text", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 40, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Microblogs such as Twitter, Facebook, and Sina Weibo (China's equivalent of Twitter), are a remarkable linguistic resource. In contrast to content from edited genres such as newswire, microblogs contain discussions of virtually every topic by numerous individuals in different languages and dialects and in different styles. In this work, we show that some microblog users post \u2030\u0170\u010eself-translated\u2030\u0170\u0165 messages targeting audiences who speak different languages, either by writing the same message in multiple languages or by retweeting translations of their original posts in a second language. We introduce a method for finding and extracting this naturally occurring parallel data. Identifying the parallel content requires solving an alignment problem, and we give an optimally efficient dynamic programming algorithm for this. Using our method, we extract nearly 3M Chinese\u2030\u0170\u0147English parallel segments from Sina Weibo using a targeted crawl of Weibo users who post in multiple languages. Additionally, from a random sample of Twitter, we are obtain substantial amounts of parallel data in multiple language pairs. Evaluation is performed by assessing the accuracy of our extraction approach relative to a manual annotation as well as in terms of utility as training data for a Chinese\u2030\u0170\u0147English machine translation system. Relative to traditional parallel data resources, the automatically extracted parallel data yields substantial translation quality improvements in translating microblog text and modest improvements in translating edited news content.", "desc": "translate text", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 41, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Words are polysemous. However, most approaches to representation learning for lexical semantics assign a single vector to every surface word type. Meanwhile, lexical ontologies such as WordNet provide a source of complementary knowledge to distributional information, including a word sense inventory. In this paper we propose two novel and general approaches for generating sense-specific word embeddings that are grounded in an ontology. The first applies graph smoothing as a postprocessing step to tease the vectors of different senses apart, and is applicable to any vector space model. The second adapts predictive maximum likelihood models that learn word embeddings with latent variables representing senses grounded in an specified ontology. Empirical results on lexical semantic tasks show that our approaches effectively captures information from both the ontology and distributional statistics. Moreover, in most cases our sense-specific models outperform other models we compare against.", "desc": "differentiate between the multiple meanings or senses of a word", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 42, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Content-based medical image retrieval (CBMIR) is an active research area for disease diagnosis and treatment but it can be problematic given the small visual variations between anatomical structures. We propose a retrieval method based on a bag-of-visual-words (BoVW) to identify discriminative characteristics between different medical images with Pruned Dictionary based on Latent Semantic Topic description. We refer to this as the PD-LST retrieval. Our method has two main components. First, we calculate a topic-word significance value for each visual word given a certain latent topic to evaluate how the word is connected to this latent topic. The latent topics are learnt, based on the relationship between the images and words, and are employed to bridge the gap between low-level visual features and high-level semantics. These latent topics describe the images and words semantically and can thus facilitate more meaningful comparisons between the words. Second, we compute an overall-word significance value to evaluate the significance of a visual word within the entire dictionary. We designed an iterative ranking method to measure overall-word significance by considering the relationship between all latent topics and words. The words with higher values are considered meaningful with more significant discriminative power in differentiating medical images. We evaluated our method on two public medical imaging datasets and it showed improved retrieval accuracy and efficiency.", "desc": "content-based medical image retrieval when there are small visual variations between anatomical structures", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 43, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Distant speech recognition (DSR) remains to be an open chal- lenge, even for the state-of-the-art deep neural network (DNN) models. Previous work has attempted to improve DNNs un- der constantly distant speech. However, in real applications, the speaker-microphone distance (SMD) can be quite dynamic, varying even within a single utterance. This paper investigates how to alleviate the impact of dynamic SMD on DNN models. Our solution is to incorporate the frame-level SMD information into DNN training. Generation of the SMD information relies on a universal extractor that is learned on a meeting corpus. We study the utility of different architectures in instantiating the SMD extractor. On our target acoustic modeling task, two approaches are proposed to build distance-aware DNN models using the SMD information: simple concatenation and distance adaptive training (DAT). Our experiments show that in the simplest case, incorporating the SMD descriptors improves word error rates of DNNs by 5.6% relative. Further optimizing SMD extraction and integration results in more gains.", "desc": "transcribe speech the when speaker-microphone distance is dynamic", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 44, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "The pervasiveness of mobile technologies today have facilitated the creation of massive crowdsourced and geotagged data from individual users in real time and at different locations in the city. Such ubiquitous user-generated data allow us to infer various patterns of human behavior, which help us understand the interactions between humans and cities. In this study, we focus on understanding users economic behavior in the city by examining the economic value from crowdsourced and geotaggged data. Specifically, we extract multiple traffic and human mobility features from publicly available data sources using NLP and geo-mapping techniques, and examine the effects of both static and dynamic features on economic outcome of local businesses. Our study is instantiated on a unique dataset of restaurant bookings from OpenTable for 3,187 restaurants in New York City from November 2013 to March 2014. Our results suggest that foot traffic can increase local popularity and business performance, while mobility and traffic from automobiles may hurt local businesses, especially the well-established chains and high-end restaurants. We also find that on average one more street closure nearby leads to a 4.7% decrease in the probability of a restaurant being fully booked during the dinner peak. Our study demonstrates the potential of how to best make use of the large volumes and diverse sources of crowdsourced and geotagged user-generated data to create matrices to predict local economic demand in a manner that is fast, cheap, accurate, and meaningful.", "desc": "understand users economic behavior in the city", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 45, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Gaze-based interaction has several benefits: naturalism, remote controllability, and easy accessibility. However, it has been mostly used for screen-based interaction with static information. In this paper, we propose a concept of gaze-based interaction that augments the physical world with social information. We demonstrate this interaction in a shopping scenario. In-store shopping is a setting where social information can augment the physical environment to better support a user's purchase decision. Based on the user's ocular point, we project the following information on the product and its surrounding surface: collective in-store gazes and purchase data, product comparison information, animation expressing ingredient of product, and online social comments. This paper presents the design of the system, the results and discussion of an informal user study, and future work.", "desc": "improve decision-making", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 46, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "In multi-person tracking scenarios, gaining access to the identity of each tracked individual is crucial for many applications such as long-term surveillance video analysis. Therefore, we propose a long-term multi-person tracker which utilizes face recognition information to not only enhance tracking performance, but also assign identities to tracked people. As face recognition information is not available in many frames, the proposed tracker utilizes manifold learning techniques to propagate identity information to frames without face recognition information. Our tracker is formulated as a constrained quadratic optimization problem, which is solved with nonnegative matrix optimization techniques. Tracking experiments performed on challenging data sets, including a 116.25 hour complex indoor tracking data set, showed that our method is effective in tracking each individual. We further explored the utility of long-term identity-aware multi-person tracking output by performing video summarization experiments based on our tracking output. Results showed that the computed trajectories were sufficient to generate a reasonable visual diary (i.e. a summary of what a person did) for different people, thus potentially opening the door to summarization of hundreds or even thousands of hours of surveillance video.", "desc": "identify and track individuals in long videos", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 47, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Modern smartphone platforms offer a multitude of useful features to their users but at the same time they are highly privacy affecting. However, smartphone platforms are not effective in properly communicating privacy risks to their users. Furthermore, common privacy risk communication approaches in smartphone app ecosystems do not consider the actual data-access behavior of individual apps in their risk assessments. Beyond privacy risks such as the leakage of single information (first-order privacy risk), we argue that privacy risk assessments and risk communication should also consider threats to user privacy coming from user-profiling and data-mining capabilities based on the long-term data-access behavior of apps (second-order privacy risk). In this paper, we introduce Styx, a novel privacy risk communication system for Android that provides users with privacy risk information based on the second-order privacy risk perspective. We discuss results from an experimental evaluation of Styx regarding its effectiveness in risk communication and its effects on user perceptions such as privacy concerns and the trustworthiness of a smartphone. Our results suggest that privacy risk information provided by Styx improves the comprehensibility of privacy risk information and helps the users in comparing different apps regarding their privacy properties. The results further suggest that an improved privacy risk communication on smartphones can increase trust towards a smartphone and reduce privacy concern.", "desc": "evaluate privacy risks to users of smartphone platforms", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 48, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "In the physical classroom, peer interactions motivate students and expand their perspective. We suggest that synchronous peer interaction can benefit massive online courses as well. Talkabout organizes students into video discussion groups and allows instructors to determine group composition and discussion content. Using Talkabout, students pick a discussion time that suits their schedule. The system groups the students into small video discussions based on instructor preferences such as gender or geographic balance. To date, 2,474 students in five massive online courses have used Talkabout to discuss topics ranging from prejudice to organizational theory. Talkabout discussions are diverse: in one course, the median six-person discussion group had students from four different countries. Students enjoyed discussing in these diverse groups: the average student participated for 66 minutes, twice the course requirement. Students in more geographically distributed groups also scored higher on the final, suggesting that distributed discussions have educational value.", "desc": "apply peer interactions to online courses", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 49, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "We propose two well-motivated ranking-based methods to enhance the performance of current state-of-the-art human activity recognition systems. First, as an improvement over the classic power normalization method, we propose a parameter-free ranking technique called rank normalization (RaN). RaN normalizes each dimension of the video features to address the sparse and bursty distribution problems of Fisher Vectors and VLAD. Second, inspired by curriculum learning, we introduce a training-free re-ranking technique called multi-class iterative re-ranking (MIR). MIR captures relationships among action classes by separating easy and typical videos from difficult ones and re-ranking the prediction scores of classifiers accordingly. We demonstrate that our methods significantly improve the performance of state-of-the-art motion features on six real-world datasets.", "desc": "recognize human activity when performance needs to be enhanced", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 50, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "We introduce UniAuth, a set of mechanisms for streamlining authentication to devices and web services. With UniAuth, a user first authenticates himself to his UniAuth client, typically his smartphone or wearable device. His client can then authenticate to other services on his behalf. In this paper, we focus on exploring the user experiences with an early iPhone prototype called Knock x Knock. To manage a variety of accounts securely in a usable way, Knock x Knock incorporates features not supported in existing password managers, such as tiered and location-aware lock control, authentication to laptops via knocking, and storing credentials locally while working with laptops seamlessly. In two field studies, 19 participants used Knock x Knock for one to three weeks with their own devices and accounts. Our participants were highly positive about Knock x Knock, demonstrating the desirability of our approach. We also discuss interesting edge cases and design implications.", "desc": "manage a variety of accounts securely in a usable way,", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 51, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Multimedia event detection has been one of the major endeavors in video event analysis. A variety of approaches have been proposed recently to tackle this problem. Among others, using semantic representation has been accredited for its promising performance and desirable ability for human-understandable reasoning. To generate semantic representation, we usually utilize several external image/video archives and apply the concept detectors trained on them to the event videos. Due to the intrinsic difference of these archives, the resulted representation is presumable to have different predicting capabilities for a certain event. Notwithstanding, not much work is available for assessing the efficacy of semantic representation from the source-level. On the other hand, it is plausible to perceive that some concepts are noisy for detecting a specific event. Motivated by these two shortcomings, we propose a bi-level semantic representation analyzing method. Regarding source-level, our method learns weights of semantic representation attained from different multimedia archives. Meanwhile, it restrains the negative influence of noisy or irrelevant concepts in the overall concept-level. In addition, we particularly focus on efficient multimedia event detection with few positive examples, which is highly appreciated in the real-world scenario. We perform extensive experiments on the challenging TRECVID MED 2013 and 2014 datasets with encouraging results that validate the efficacy of our proposed approach.", "desc": "detect video events with multimedia analysis", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 52, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Many information-extraction and knowledge base construction systems are addressing the challenge of deriving knowledge from text. A key problem in constructing these knowledge bases from sources like the web is overcoming the erroneous and incomplete informa- tion found in millions of candidate extractions. To solve this problem, we turn to semantics \u2030\u0170\u00d3 using ontological constraints between candidate facts to eliminate errors. In this article, we represent the desired knowledge base as a knowledge graph and introduce the problem of knowledge graph identifica- tion, collectively resolving the entities, labels, and relations present in the knowledge graph. Knowledge graph identification requires reasoning jointly over millions of extractions simultane- ously, posing a scalability challenge to many approaches. We use probabilistic soft logic (PSL), a recently introduced statistical relational learning framework, to implement an efficient solution to knowledge graph identification and present state-of-the-art results for knowledge graph construction while performing an order of magnitude faster than competing methods.", "desc": "extract information for a knowledgebase when the candidate extractions have erronious and incomplete information", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 53, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Studying characters plays a vital role in computationally representing and interpreting narratives. Unlike previous work, which has focused on inferring character roles, we focus on the problem of modeling their relationships. Rather than assuming a fixed relationship for a character pair, we hypothesize that relationships temporally evolve with the progress of the narrative, and formulate the problem of relationship modeling as a structured prediction problem. We propose a semi-supervised framework to learn relationship sequences from fully as well as partially labeled data. We present a Markovian model capable of accumulating historical beliefs about the relationship and status changes. We  use a set of rich linguistic and semantically motivated features that incorporate world knowledge to investigate the textual content of narrative. We empirically demonstrate that such a framework outperforms competitive baselines.", "desc": "interperet narrative texts computationally", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 54, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "While neural networks have been successfully applied to many NLP tasks the resulting vector-based models are very difficult to interpret. For example it's not clear how they achieve {\\em compositionality}, building sentence meaning from the meanings of words and phrases. In this paper we describe four strategies for visualizing compositionality in neural models for NLP, inspired by similar work in computer vision. We first plot unit values to visualize compositionality of negation, intensification, and concessive clauses, allow us to see well-known markedness asymmetries in negation. We then introduce three simple and straightforward methods for visualizing a unit's {\\em salience}, the amount it contributes to the final composed meaning: (1) gradient back-propagation, (2) the variance of a token from the average word node, (3) LSTM-style gates that measure information flow. We test our methods on sentiment using simple recurrent nets and LSTMs. Our general-purpose methods may have wide applications for understanding compositionality and other semantic properties of deep networks , and also shed light on why LSTMs outperform simple recurrent nets,", "desc": "visualize compositionality in neural models for natural langauge processing", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 55, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Provides an overview of a speech-to-text (STT) and keyword search (KWS) system architecture build primarily on the top of the Kaldi toolkit and expands on a few highlights. The system was developed as a part of the research efforts of the Radical team while participating in the IARPA Babel program. Our aim was to develop a general system pipeline which could be easily and rapidly deployed in any language, independently on the language script and phonological and linguistic features of the language.", "desc": "transcribe speech using a speech-to-text (STT) and keyword search (KWS) system architecture", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 56, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "In predicate invention (PI), new predicates are introduced into a logical theory, usually by rewriting a group of closely-related rules to use a common invented predicate as a \u2030\u0170\u010esubroutine\u2030\u0170\u0165. PI is difficult, since a poorly-chosen invented predicate may lead to error cascades. Here we suggest a \u2030\u0170\u010esoft\u2030\u0170\u0165 version of predicate invention: instead of explicitly creating new predicates, we implicitly group closely-related rules by using structured sparsity to regularize their parameters together. We show that soft PI, unlike hard PI, consistently improves over previous strong baselines for structure-learning on two large-scale tasks.", "desc": "invent new predicates for a logical theory when a poorly-chosen predicate causes cascading errors", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 57, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "A standard pipeline for statistical relational learning involves two steps: one first constructs the knowledge base (KB) from text, and then performs the learning and reasoning tasks using probabilistic first-order logics. However, a key issue is that information extraction (IE) er- rors from text affect the quality of the KB, and propagate to the reasoning task. In this paper, we propose a statistical rela- tional learning model for joint information extraction and reasoning. More specifically, we incorporate context-based entity extraction with structure learning (SL) in a scalable probabilistic logic framework. We then propose a latent context invention (LCI) approach to improve the per- formance. In experiments, we show that our approach outperforms state-of-the-art baselines over three real-world Wikipedia datasets from multiple domains; that joint learning and inference for IE and SL significantly improve both tasks; that latent context invention further improves the results.", "desc": "extract information for a knowledgebase accurately", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 58, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Coreference resolution is one of the first stages in deep language understanding and its importance has been well recognized in the natural language processing community. In this paper, we propose a generative, unsupervised ranking model for entity coreference resolution by introducing resolution mode variables. Our unsupervised system achieves 58.44% F1 score of the CoNLL metric on the English data from the CoNLL-2012 shared task (Pradhan et al., 2012), outperforming the Stanford deterministic system (Lee et al., 2013) by 3.01%.", "desc": "resolve coreferencing", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 59, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Understanding the purpose of why sensitive data is used could help improve privacy as well as enable new kinds of access control. In this paper, we introduce a new technique for inferring the purpose of sensitive data usage in the context of Android smartphone apps. We extract multiple kinds of features from decompiled code, focusing on app-specific features and text-based features. These features are then used to train a machine learning classifier. We have evaluated our approach in the context of two sensitive permissions, namely ACCESS_FINE_LOCATION and READ_CONTACT_LIST, and achieved an accuracy of about 85% and 94% respectively in inferring purposes. We have also found that text-based features alone are highly effective in inferring purposes.", "desc": "access accounts with improved privacy and enable new kinds of access", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 60, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "In this paper, we focus on automatically detecting events in unconstrained videos without the use of any visual training exemplars. In principle, zero-shot learning makes it possible to train an event detection model based on the assumption that events (e.g. \\emph{birthday party}) can be described by multiple mid-level semantic concepts (e.g. \"blowing candle\", \"birthday cake\"). Towards this goal, we first pre-train a bundle of concept classifiers using data from other sources. Then we evaluate the semantic correlation of each concept \\wrt the event of interest and pick up the relevant concept classifiers, which are applied on all test videos to get multiple prediction score vectors. While most existing systems combine the predictions of the concept classifiers with fixed weights, we propose to learn the optimal weights of the concept classifiers for each testing video by exploring a set of online available videos with free-form text descriptions of their content. To validate the effectiveness of the proposed approach, we have conducted extensive experiments on the latest TRECVID MEDTest 2014, MEDTest 2013 and CCV dataset. The experimental results confirm the superiority of the proposed approach.", "desc": "detect events in unconstrained videos automatically without the use of any visual training exemplars", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 61, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "In particular for 'low resource' Keyword Search (KWS) and Speech-to-Text (STT) tasks, more untranscribed test data may be available than training data. Several approaches have been proposed to make this data useful during system development, even when initial systems have Word Error Rates (WER) above 70%. In this paper, we present a set of experiments on low-resource languages in telephony speech quality in Assamese, Bengali, Lao, Haitian, Zulu, and Tamil, demonstrating the impact that such techniques can have, in particular learning robust bottle-neck features on the test data. In the case of Tamil, when significantly more test data than training data is available, we integrated semi-supervised training and speaker adaptation on the test data, and achieved significant additional improvements in STT and KWS.", "desc": "transcribe speech when more untranscribed test data than training data is available", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 62, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "In acoustic modeling, speaker adaptive training (SAT) has been a long-standing technique for the traditional Gaussian mixture models (GMMs). Acoustic models trained with SAT become independent of training speakers and generalize better to unseen testing speakers. This paper ports the idea of SAT to deep neural networks (DNNs), and proposes a framework to perform feature-space SAT for DNNs. Using i-vectors as speaker representations, our framework learns an adaptation neural network to derive speaker-normalized features. Speaker adaptive models are obtained by fine-tuning DNNs in such a feature space. This framework can be applied to various feature types and network structures, posing a very general SAT solution. In this paper, we fully investigate how to build SAT-DNN models effectively and efficiently. First, we study the optimal configurations of SAT-DNNs for large-scale acoustic modeling tasks. Then, after presenting detailed comparisons between SAT-DNNs and the existing DNN adaptation methods, we propose to combine SAT-DNNs and model-space DNN adaptation during decoding. Finally, to accelerate learning of SAT-DNNs, a simple yet effective strategy, frame skipping, is employed to reduce the size of training data. Our experiments show that compared with a strong DNN baseline, the SAT-DNN model achieves 13.5% and 17.5% relative improvement on word error rates (WERs), without and with model-space adaptation applied respectively. Data reduction based on frame skipping results in 2 \u011a\u0143 speed-up for SAT-DNN training, while causing negligible WER loss on the testing data.", "desc": "perform feature-space Speaker Adaptive Training for Deep Neural Networks", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 63, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Building an intelligent agent that simulates human learning of math and science could potentially benefit both cognitive science, by contributing to the understanding of human learning, and artificial intelligence, by advancing the goal of creating human-level intelligence. However, constructing such a learning agent currently requires manual encoding of prior domain knowledge; in addition to being a poor model of human acquisition of prior knowledge, manual knowledge-encoding is both time-consuming and error-prone. Previous research has shown that one of the key factors that differentiates experts and novices is their different representations of knowledge. Experts view the world in terms of deep functional features, while novices view it in terms of shallow perceptual features. Moreover, since the performance of learning algorithms is sensitive to representation, the deep features are also important in achieving effective machine learning. In this paper, we present an efficient algorithm that acquires representation knowledge in the form of \u2030\u0170\u010edeep features\u2030\u0170\u0165, and demonstrate its effectiveness in the domain of algebra as well as synthetic domains. We integrate this algorithm into a machine-learning agent, SimStudent, which learns procedural knowledge by observing a tutor solve sample problems, and by getting feedback while actively solving problems on its own. We show that learning \u2030\u0170\u010edeep features\u2030\u0170\u0165 reduces the requirements for knowledge engineering. Moreover, we propose an approach that automatically discovers student models using the extended SimStudent. By fitting the discovered model to real student learning curve data, we show that it is a better student model than human-generated models, and demonstrate how the discovered model may be used to improve a tutoring system's instructional strategy.", "desc": "simulate human learning of math and science with an intelligent agent", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 64, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "This paper describes GenProg, an automated method for repairing defects in off-the-shelf, legacy programs without formal specifications, program annotations, or special coding practices. GenProg uses an extended form of genetic programming to evolve a program variant that retains required functionality but is not susceptible to a given defect, using existing test suites to encode both the defect and required functionality. Structural differencing algorithms and delta debugging reduce the difference between this variant and the original program to a minimal repair. We describe the algorithm and report experimental results of its success on 16 programs totaling 1.25 M lines of C code and 120K lines of module code, spanning eight classes of defects, in 357 seconds, on average. We analyze the generated repairs qualitatively and quantitatively to demonstrate that the process efficiently produces evolved programs that repair the defect, are not fragile input memorizations, and do not lead to serious degradation in functionality.", "desc": "repair defects in off-the-shelf programs without formal specifications, program annotations, or special coding practices", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 65, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Multimedia event detection (MED) and multimedia event recounting (MER) are fundamental tasks in managing large amounts of unconstrained web videos, and have attracted a lot of attention in recent years. Most existing systems perform MER as a post-processing step on top of the MED results. In order to leverage the mutual benefits of the two tasks, we propose a joint framework that simultaneously detects high-level events and localizes the indicative concepts of the events. Our premise is that a good recounting algorithm should not only explain the detection result, but should also be able to assist detection in the first place. Coupled in a joint optimization framework, recounting improves detection by pruning irrelevant noisy concepts while detection directs recounting to the most discriminative evidences. To better utilize the powerful and interpretable semantic video representation, we segment each video into several shots and exploit the rich temporal structures at shot level. The consequent computational challenge is carefully addressed through a significant improvement of the current ADMM algorithm, which, after eliminating all inner loops and equipping novel closed-form solutions for all intermediate steps, enables us to efficiently process extremely large video corpora. We test the proposed method on the large scale TRECVID MEDTest 2014 and MEDTest 2013 datasets, and obtain very promising results for both MED and MER.", "desc": "perform MER with MED simultaneously", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 66, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "In this chapter we describe the design, development and application of the Helix Metamorphic Shield (HMS). The HMS: (1) continuously shifts the program\u2030\u0170\u015es attack surface in both the spatial and temporal dimensions, and (2), reduces the program\u2030\u0170\u015es attack surface by applying novel evolutionary algorithms to automatically repair vulnerabilities. The symbiotic interplay between shifting and reducing the attack surface results in the automated evolution of new program variants whose quality improves over time.", "desc": "protect program from attack", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 67, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "large-scale idea generation platforms often expose ideators to previous ideas. However, research suggests people generate better ideas if they see abstracted solution paths (e.g., descriptions of solution approaches generated through human sensemaking) rather than being inundated with all prior ideas. Automated and semi-automated methods can also offer interpretations of earlier ideas. To benefit from sensemaking in practice with limited resources, ideation platform developers need to weigh the cost-quality tradeoffs of different methods for surfacing solution paths. To explore this, we conducted an online study where 245 participants generated ideas for two problems in one of five conditions: 1) no stimuli, 2) exposure to all prior ideas, or solution paths extracted from prior ideas using 3) a fully automated workflow, 4) a hybrid human-machine approach, and 5) a fully manual approach. Contrary to expectations, human-generated paths did not improve ideation (as meas- ured by fluency and breadth of ideation) over simply showing all ideas. Machine-generated paths sometimes significantly improved fluency and breadth of ideation over no ideas (although at some cost to idea quality). These findings suggest that automated sensemaking can improve idea generation, but we need more research to understand the value of human sensemaking for crowd ideation.", "desc": "generate better ideas when ideators see abstracted solution paths", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 68, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "State-of-the-art sequence labeling systems traditionally require large amounts of task-specific knowledge in the form of hand-crafted features and data pre-processing. In this paper, we introduce a novel neutral network architecture that benefits from both word- and character-level representations automatically, by using combination of bidirectional LSTM, CNN and CRF. Our system is truly end-to-end, requiring no feature engineering or data pre-processing, thus making it applicable to a wide range of sequence labeling tasks on different languages. We evaluate our system on two data sets for two sequence labeling tasks --- Penn Treebank WSJ corpus for part-of-speech (POS) tagging and CoNLL 2003 corpus for named entity recognition (NER). We obtain state-of-the-art performance on both the two data --- 97.55\\% accuracy for POS tagging and 91.21\\% F1 for NER.", "desc": "sequence labling without  large amounts of task-specific prior knowledge", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 69, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Twitter, Flickr, Instagram, and other public social media sites have inspired lots of analysis of public geotagged posts. In order to understand these posts, it is important to know where their authors live. Based on a study of 195 prolific Twitter users in the Pittsburgh area, and their ground truth home locations, we show that simple algorithms can find about 80% of people\u2030\u0170\u015es home addresses within 1 kilometer. We show why this is near the upper bound of feasibility, show that studying as few as 10 tweets can achieve almost the same results, and dis- cuss implications for future social media analyses.", "desc": "find the source location of social media data", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 70, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "One important challenge for probabilistic logics is reasoning with very large knowledge bases (KBs) of imperfect information, such as those produced by modern web-scale information extraction systems. One scalability problem shared by many probabilistic logics is that answering queries involves \u2030\u0170\u010egrounding\u2030\u0170\u0165 the query\u2030\u0170\u00d3i.e., mapping it to a propositional representation\u2030\u0170\u00d3and the size of a \u2030\u0170\u010egrounding\u2030\u0170\u0165 grows with database size. To address this bottleneck, we present a first-order probabilistic language called ProPPR in which approximate \u2030\u0170\u010elocal groundings\u2030\u0170\u0165 can be constructed in time independent of database size. Technically, ProPPR is an extension to stochastic logic programs that is biased towards short derivations; it is also closely related to an earlier relational learning algorithm called the path ranking algorithm. We show that the problem of constructing proofs for this logic is related to computation of personalized PageRank on a linearized version of the proof space, and based on this connection, we develop a provably-correct approximate grounding scheme, based on the PageRank\u2030\u0170\u0147Nibble algorithm. Building on this, we develop a fast and easily-parallelized weight-learning algorithm for ProPPR. In our experiments, we show that learning for ProPPR is orders of magnitude faster than learning for Markov logic networks; that allowing mutual recursion (joint learning) in KB inference leads to improvements in performance; and that ProPPR can learn weights for a mutually recursive program with hundreds of clauses defining scores of interrelated predicates over a KB containing one million entities.", "desc": "reason with very large knowledge bases (KBs) of imperfect information", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 71, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Friendsourcing consists of broadcasting questions and help requests to friends on social networking sites. Despite its potential value, friendsourcing requests often fall on deaf ears. One way to improve response rates and motivate friends to undertake more effortful tasks may be to offer extrinsic rewards, such as money or a gift, for responding to friendsourcing requests. However, past research suggests that these extrinsic rewards can have unintended consequences, including undermining intrinsic motivations and undercutting the relationship between people. To explore the effects of extrinsic reward on friends\u2030\u0170\u015e response rate and perceived relationship, we conducted an experiment on a new friendsourcing platform - Mobilyzr. Results indicate that large extrinsic rewards increase friends\u2030\u0170\u015e response rates without reducing the relationship strength between friends. Additionally, the extrinsic rewards allow requesters to explain away the failure of friendsourcing requests and thus preserve their perceptions of relationship ties with friends.", "desc": "improve friendsourcing, the idea that friends can ask eachother for help", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 72, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Peer assessment helps students reflect and exposes them to different ideas. It scales assessment and allows large online classes to use open-ended assignments. However, it requires students to spend significant time grading. How can we lower this grading burden while maintaining quality? This paper integrates peer and machine grading to preserve the robustness of peer assessment and lower grading burden. In the identify-verify pattern, a grading algorithm first predicts a student grade and estimates confidence, which is used to estimate the number of peer raters required. Peers then identify key features of the answer using a rubric. Finally, other peers verify whether these feature labels were accurately applied. This pattern adjusts the number of peers that evaluate an answer based on algorithmic confidence and peer agreement. We evaluated this pattern with 1370 students in a large, online design class. With only 54% of the student grading time, the identify-verify pattern yields 80-90% of the accuracy obtained by taking the median of three peer scores, and provides more detailed feedback. A second experiment found that verification dramatically improves accuracy with more raters, with a 20% gain over the peer-median with four raters. However, verification also leads to lower initial trust in the grading system. The identify-verify pattern provides an example of how peer work and machine learning can combine to improve the learning experience.", "desc": "reduce the burden of peer grading while maintaining quality", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 73, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available. In this paper, we introduce two new neural architectures---one based on bidirectional LSTMs and conditional random fields, and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers. Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora. Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers.", "desc": "recognize named entities without relying on hand-crafted features or domain-specific knowledge", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 74, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Programming languages often include specialized syntax for common datatypes (e.g. lists) and some also build in support for specific specialized datatypes (e.g. regular expressions), but user-defined types must use general-purpose syntax. Frustration with this causes developers to use strings, rather than structured data, with alarming frequency, leading to correctness, performance, security, and usability issues. Allowing library providers to modularly extend a language with new syntax could help address these issues. Unfortunately, prior mechanisms either limit expressiveness or are not safely composable: individually unambiguous extensions can still cause ambiguities when used together. We introduce type-specific languages (TSLs): logic associated with a type that determines how the bodies of generic literals, able to contain arbitrary syntax, are parsed and elaborated, hygienically. The TSL for a type is invoked only when a literal appears where a term of that type is expected, guaranteeing non-interference. We give evidence supporting the applicability of this approach and formally specify it with a bidirectionally typed elaboration semantics for the Wyvern programming language.", "desc": "Allow library providers to modularly extend a language with new syntax", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 75, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Early detection and precise characterization of emerging topics in text streams can be highly useful in applications such as timely and targeted public health interventions and discovering evolving regional business trends. Many methods have been proposed for detecting emerging events in text streams using topic modeling. However, these methods have numerous shortcomings that make them unsuitable for rapid detection of locally emerging events on massive text streams. In this paper, we describe Semantic Scan (SS) that has been developed specifically to overcome these shortcomings in detecting new spatially compact events in text streams. Semantic Scan integrates novel contrastive topic modeling with online document assignment and principled likelihood ratio-based spatial scanning to identify emerging events with unexpected patterns of keywords hidden in text streams. This enables more timely and accurate detection and characterization of anomalous, spatially localized emerging events. Semantic Scan does not require manual intervention or labeled training data, and is robust to noise in real-world text data since it identifies anomalous text patterns that occur in a cluster of new documents rather than an anomaly in a single new document. We compare Semantic Scan to alternative state-of-the-art methods such as Topics over Time, Online LDA, and Labeled LDA on two real-world tasks: (i) a disease surveillance task monitoring free-text Emergency Department chief complaints in Allegheny County, and (ii) an emerging business trend detection task based on Yelp reviews. On both tasks, we find that Semantic Scan provides significantly better event detection and characterization accuracy than competing approaches, while providing up to an order of magnitude speedup.", "desc": "detect new spatially compact events in text streams", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 76, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Combining deep neural networks with structured logic rules is desirable to harness flexibility and reduce unpredictability of the neural models. We propose a general framework capable of enhancing various types of neural networks (e.g., CNNs and RNNs) with declarative first-order logic rules. Specifically, we develop an iterative distillation method that transfers the structured information of logic rules into the weights of neural networks. We deploy the framework on a CNN for sentiment analysis, and an RNN for named entity recognition. With a few highly intuitive rules, we obtain substantial improvements and achieve state-of-the-art or comparable results to previous best-performing systems.", "desc": "Combine deep neural networks with structured logic rules", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 77, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "The performance of automatic speech recognition (ASR) has improved tremendously due to the application of deep neu- ral networks (DNNs). Despite this progress, building a new ASR system remains a challenging task, requiring various resources, multiple training stages and significant expertise. This paper presents our Eesen framework which drastically simplifies the existing pipeline to build state-of-the-art ASR systems. Acoustic modeling in Eesen involves learning a single recurrent neural network (RNN) predicting context- independent targets (phonemes or characters). To remove the need for pre-generated frame labels, we adopt the connectionist temporal classification (CTC) objective function to infer the alignments between speech and label sequences. A distinctive feature of Eesen is a generalized decoding approach based on weighted finite-state transducers (WFSTs), which enables the efficient incorporation of lexicons and language models into CTC decoding. Experiments show that compared with the standard hybrid DNN systems, Eesen achieves comparable word error rates (WERs), while at the same time speeding up decoding significantly.", "desc": "transcribe speech", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 78, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "While there has been much research on automatically constructing structured Knowledge Bases (KBs), most of it has focused on generating facts to populate a KB. However, a useful KB must go beyond facts. For example, glosses (short natural language definitions) have been found to be very useful in tasks such as Word Sense Disambiguation. However, the important problem of Automatic Gloss Finding, i.e., assigning glosses to entities in an initially gloss-free KB, is relatively unexplored. We address that gap in this paper. In particular, we propose GLOFIN, a hierarchical semi-supervised learning algorithm for this problem which makes effective use of limited amounts of supervision and available ontological constraints. To the best of our knowledge, GLOFIN is the first system for this task. Through extensive experiments on real-world datasets, we demonstrate GLOFIN's effectiveness. It is encouraging to see that GLOFIN outperforms other state-of-the-art SSL algorithms, especially in low supervision settings. We also demonstrate GLOFIN's robustness to noise through experiments on a wide variety of KBs, ranging from user contributed (e.g., Freebase) to automatically constructed (e.g., NELL). To facilitate further research in this area, we have made the datasets and code used in this paper publicly available.", "desc": "connect glosses (short natural language definitions) with facts in a knowledge base", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 79, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "In this paper, we propose a novel approach for Word Sense Disambiguation (WSD) of verbs that can be applied directly in the event mention detection task to classify event types. By using the PropStore, a database of relations between words, our approach disambiguates senses of verbs by utilizing the information of verbs that appear in similar syntactic contexts. Importantly, the resource our approach requires is only a word sense dictionary, without any annotated sentences or structures and relations between different senses (as in WordNet). Our approach can be extended to disambiguate senses of words for parts of speech besides verbs.", "desc": "disambiguate senses of verbs", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 80, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Understanding the social roles played by contributors to online communities can facilitate the process of task routing. In this work, we develop new techniques to find roles in Wikipedia based on editors\u2030\u0170\u015e low-level edit types and investigate how work contributed by people from different roles affect the article quality. To do this, we first built machinelearning models to automatically identify the edit categories associated with edits. We then applied a graphical model analogous to Latent Dirichlet Allocation to uncover the latent roles in editors\u2030\u0170\u015e edit histories. Applying this technique revealed eight different roles editors play. Finally, we validated how our identified roles collaborate to improve the quality of articles. The results demonstrate that editors carrying on different roles contribute differently in terms of edit categories and articles in different quality stages need different types of editors. Implications for editor role identification and the validation of role contribution are discussed.", "desc": "Understand the social roles played by contributors to online communities", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 81, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Typestate reflects how the legal operations on imperative objects can change at runtime as their internal state changes. A typestate checker can statically ensure, for instance, that an object method is only called when the object is in a state for which the operation is well defined. Prior work has shown how modular typestate checking can be achieved thanks to access permissions and state guarantees. However, typestate was not treated as a primitive language concept: typestate checkers are an additional verification layer on top of an existing language. In contrast, a typestate-oriented programming (TSOP) language directly supports expressing typestates. For example, in the Plaid programming language, the typestate of an object directly corresponds to its class, and that class can change dynamically. Plaid objects have not only typestate-dependent interfaces but also typestate-dependent behaviors and runtime representations. This article lays foundations for TSOP by formalizing a nominal object-oriented language with mutable state that integrates typestate change and typestate checking as primitive concepts. We first describe a statically typed language\u2030\u0170\u00d3Featherweight Typestate (FT)\u2030\u0170\u00d3where the types of object references are augmented with access permissions and state guarantees. We describe a novel flow-sensitive permission-based type system for FT. Because static typestate checking is still too rigid for some applications, we then extend this language into a gradually typed language\u2030\u0170\u00d3Gradual Featherweight Typestate (GFT). This language extends the notion of gradual typing to account for typestate: gradual typestate checking seamlessly combines static and dynamic checking by automatically inserting runtime checks into programs. The gradual type system of GFT allows programmers to write dynamically safe code even when the static type checker can only partly verify it.", "desc": "develop typestate-oriented programming", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 82, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Vast quantities of videos are now being captured at astonishing rates, but the majority of these are not labelled.  To cope with such data, we consider the task of content-based activity recognition in videos without any manually labelled examples, also known as zero-shot video recognition. To achieve this, videos are represented in  terms of detected visual concepts, which are then scored as relevant or irrelevant according to their similarity with a given textual query.  In this paper, we propose a more robust approach for scoring concepts in order to alleviate many of the brittleness and low precision problems of previous work. Not only do we jointly consider semantic relatedness, visual reliability, and discriminative power. To handle noise and non-linearities in the ranking scores of the selected concepts, we propose a novel pairwise order matrix approach for score aggregation. Extensive experiments on the large-scale TRECVID Multimedia Event Detection data show the superiority of our approach.", "desc": "recognize activity in videos using content-based recognition without manually labelled examples", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 83, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Automatic real-time captioning provides immediate and on demand access to spoken content in lectures or talks, and is a crucial accommodation for deaf and hard of hearing (DHH) people. However, in the presence of specialized content, like in technical talks, automatic speech recognition (ASR) still makes mistakes which may render the output incomprehensible. In this paper, we introduce a new approach, which allows audience or crowd workers, to quickly correct errors that they spot in ASR output. Prior approaches required the crowd worker to manually \u2030\u0170\u010eedit\u2030\u0170\u0165 the ASR hypothesis by selecting and replacing the text, which is not suitable for real-time scenarios. Our approach is faster and allows the worker to simply type corrections for misrecognized words as soon as he or she spots them. The system then finds the most likely position for the correction in the ASR output using keyword search (KWS) and stitches the word into the ASR output. Our work demonstrates the potential of computation to incorporate human input quickly enough to be usable in real-time scenarios, and may be a better method for providing this vital accommodation to DHH people.", "desc": "speed up manual correction of captions", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 84, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "We present an approach for the detection of coordinate-term relationships between entities from the software domain, that refer to Java classes. Usually, relations are found by examining corpus statistics associated with text entities. In some technical domains, however, we have access to additional information about the real-world objects named by the entities, suggesting that coupling information about the \"grounded\" entities with corpus statistics might lead to improved methods for relation discovery. To this end, we develop a similarity measure for Java classes using distributional information about how they are used in software, which we combine with corpus statistics on the distribution of contexts in which the classes appear in text. Using our approach, cross-validation accuracy on this dataset can be improved dramatically, from around 60% to 88%. Human labeling results show that our classifier has an F1 score of 86% over the top 1000 predicted pairs.", "desc": "relate software entities (java classes) to real world objects", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 85, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "History event related knowledge is precious and imagery is a powerful medium that records diverse information about the event. In this paper, we propose to automatically construct an image profile given a one sentence description of the historic event which contains where, when, who and what elements. Such a simple input requirement makes our solution easy to scale up and support a wide range of culture preservation and curation related applications ranging from wikipedia enrichment to history education. However, history relevant information on the web is available as \"wild and dirty\" data, which is quite different from clean, manually curated and structured information sources. There are two major challenges to build our proposed image profiles: 1) unconstrained image genre diversity. We categorize images into genres of documents/maps, paintings or photos. Image genre classification involves a full-spectrum of features from low-level color to high-level semantic concepts. 2) image content diversity. It can include faces, objects and scenes. Furthermore, even within the same event, the views and subjects of images are diverse and correspond to different facets of the event. To solve this challenge, we group images at two levels of granularity: iconic image grouping and facet image grouping. These require different types of features and analysis from near exact matching to soft semantic similarity. We develop a full-range feature analysis module which is composed of several levels, each suitable for different types of image analysis tasks. The wide range of features are based on both classical hand-crafted features and different layers of a convolutional neural network. We compare and study the performance of the different levels in the full-range features and show their effectiveness on handling such a wild, unconstrained dataset.", "desc": "manage unconstrained image genre diversity", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 86, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Microblogs such as Twitter, Facebook, and Sina Weibo (China's equivalent of Twitter), are a remarkable linguistic resource. In contrast to content from edited genres such as newswire, microblogs contain discussions of virtually every topic by numerous individuals in different languages and dialects and in different styles. In this work, we show that some microblog users post \u2030\u0170\u010eself-translated\u2030\u0170\u0165 messages targeting audiences who speak different languages, either by writing the same message in multiple languages or by retweeting translations of their original posts in a second language. We introduce a method for finding and extracting this naturally occurring parallel data. Identifying the parallel content requires solving an alignment problem, and we give an optimally efficient dynamic programming algorithm for this. Using our method, we extract nearly 3M Chinese\u2030\u0170\u0147English parallel segments from Sina Weibo using a targeted crawl of Weibo users who post in multiple languages. Additionally, from a random sample of Twitter, we are obtain substantial amounts of parallel data in multiple language pairs. Evaluation is performed by assessing the accuracy of our extraction approach relative to a manual annotation as well as in terms of utility as training data for a Chinese\u2030\u0170\u0147English machine translation system. Relative to traditional parallel data resources, the automatically extracted parallel data yields substantial translation quality improvements in translating microblog text and modest improvements in translating edited news content.", "desc": "solve an alignment problem to extract naturally occurring parallel data in social media user's self-translations", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 87, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Words are polysemous. However, most approaches to representation learning for lexical semantics assign a single vector to every surface word type. Meanwhile, lexical ontologies such as WordNet provide a source of complementary knowledge to distributional information, including a word sense inventory. In this paper we propose two novel and general approaches for generating sense-specific word embeddings that are grounded in an ontology. The first applies graph smoothing as a postprocessing step to tease the vectors of different senses apart, and is applicable to any vector space model. The second adapts predictive maximum likelihood models that learn word embeddings with latent variables representing senses grounded in an specified ontology. Empirical results on lexical semantic tasks show that our approaches effectively captures information from both the ontology and distributional statistics. Moreover, in most cases our sense-specific models outperform other models we compare against.", "desc": "differentiate between the multiple meanings or senses of a word", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 88, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "The pervasiveness of mobile technologies today have facilitated the creation of massive crowdsourced and geotagged data from individual users in real time and at different locations in the city. Such ubiquitous user-generated data allow us to infer various patterns of human behavior, which help us understand the interactions between humans and cities. In this study, we focus on understanding users economic behavior in the city by examining the economic value from crowdsourced and geotaggged data. Specifically, we extract multiple traffic and human mobility features from publicly available data sources using NLP and geo-mapping techniques, and examine the effects of both static and dynamic features on economic outcome of local businesses. Our study is instantiated on a unique dataset of restaurant bookings from OpenTable for 3,187 restaurants in New York City from November 2013 to March 2014. Our results suggest that foot traffic can increase local popularity and business performance, while mobility and traffic from automobiles may hurt local businesses, especially the well-established chains and high-end restaurants. We also find that on average one more street closure nearby leads to a 4.7% decrease in the probability of a restaurant being fully booked during the dinner peak. Our study demonstrates the potential of how to best make use of the large volumes and diverse sources of crowdsourced and geotagged user-generated data to create matrices to predict local economic demand in a manner that is fast, cheap, accurate, and meaningful.", "desc": "use geotagged user data to create matrices to predict local economic demand", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 89, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Gaze-based interaction has several benefits: naturalism, remote controllability, and easy accessibility. However, it has been mostly used for screen-based interaction with static information. In this paper, we propose a concept of gaze-based interaction that augments the physical world with social information. We demonstrate this interaction in a shopping scenario. In-store shopping is a setting where social information can augment the physical environment to better support a user's purchase decision. Based on the user's ocular point, we project the following information on the product and its surrounding surface: collective in-store gazes and purchase data, product comparison information, animation expressing ingredient of product, and online social comments. This paper presents the design of the system, the results and discussion of an informal user study, and future work.", "desc": "augment the physical world with social information", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 90, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Modern smartphone platforms offer a multitude of useful features to their users but at the same time they are highly privacy affecting. However, smartphone platforms are not effective in properly communicating privacy risks to their users. Furthermore, common privacy risk communication approaches in smartphone app ecosystems do not consider the actual data-access behavior of individual apps in their risk assessments. Beyond privacy risks such as the leakage of single information (first-order privacy risk), we argue that privacy risk assessments and risk communication should also consider threats to user privacy coming from user-profiling and data-mining capabilities based on the long-term data-access behavior of apps (second-order privacy risk). In this paper, we introduce Styx, a novel privacy risk communication system for Android that provides users with privacy risk information based on the second-order privacy risk perspective. We discuss results from an experimental evaluation of Styx regarding its effectiveness in risk communication and its effects on user perceptions such as privacy concerns and the trustworthiness of a smartphone. Our results suggest that privacy risk information provided by Styx improves the comprehensibility of privacy risk information and helps the users in comparing different apps regarding their privacy properties. The results further suggest that an improved privacy risk communication on smartphones can increase trust towards a smartphone and reduce privacy concern.", "desc": "evaluate effect of the platform on user perceptions such as privacy concerns and the trustworthiness of a smartphone", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 91, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "We propose two well-motivated ranking-based methods to enhance the performance of current state-of-the-art human activity recognition systems. First, as an improvement over the classic power normalization method, we propose a parameter-free ranking technique called rank normalization (RaN). RaN normalizes each dimension of the video features to address the sparse and bursty distribution problems of Fisher Vectors and VLAD. Second, inspired by curriculum learning, we introduce a training-free re-ranking technique called multi-class iterative re-ranking (MIR). MIR captures relationships among action classes by separating easy and typical videos from difficult ones and re-ranking the prediction scores of classifiers accordingly. We demonstrate that our methods significantly improve the performance of state-of-the-art motion features on six real-world datasets.", "desc": "enhance the performance of human activity recognition systems", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 92, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Multimedia event detection has been one of the major endeavors in video event analysis. A variety of approaches have been proposed recently to tackle this problem. Among others, using semantic representation has been accredited for its promising performance and desirable ability for human-understandable reasoning. To generate semantic representation, we usually utilize several external image/video archives and apply the concept detectors trained on them to the event videos. Due to the intrinsic difference of these archives, the resulted representation is presumable to have different predicting capabilities for a certain event. Notwithstanding, not much work is available for assessing the efficacy of semantic representation from the source-level. On the other hand, it is plausible to perceive that some concepts are noisy for detecting a specific event. Motivated by these two shortcomings, we propose a bi-level semantic representation analyzing method. Regarding source-level, our method learns weights of semantic representation attained from different multimedia archives. Meanwhile, it restrains the negative influence of noisy or irrelevant concepts in the overall concept-level. In addition, we particularly focus on efficient multimedia event detection with few positive examples, which is highly appreciated in the real-world scenario. We perform extensive experiments on the challenging TRECVID MED 2013 and 2014 datasets with encouraging results that validate the efficacy of our proposed approach.", "desc": "balance different predicting capabilities for each source", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 93, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Studying characters plays a vital role in computationally representing and interpreting narratives. Unlike previous work, which has focused on inferring character roles, we focus on the problem of modeling their relationships. Rather than assuming a fixed relationship for a character pair, we hypothesize that relationships temporally evolve with the progress of the narrative, and formulate the problem of relationship modeling as a structured prediction problem. We propose a semi-supervised framework to learn relationship sequences from fully as well as partially labeled data. We present a Markovian model capable of accumulating historical beliefs about the relationship and status changes. We  use a set of rich linguistic and semantically motivated features that incorporate world knowledge to investigate the textual content of narrative. We empirically demonstrate that such a framework outperforms competitive baselines.", "desc": "model characters' relationships in a narrative text", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 94, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "In predicate invention (PI), new predicates are introduced into a logical theory, usually by rewriting a group of closely-related rules to use a common invented predicate as a \u2030\u0170\u010esubroutine\u2030\u0170\u0165. PI is difficult, since a poorly-chosen invented predicate may lead to error cascades. Here we suggest a \u2030\u0170\u010esoft\u2030\u0170\u0165 version of predicate invention: instead of explicitly creating new predicates, we implicitly group closely-related rules by using structured sparsity to regularize their parameters together. We show that soft PI, unlike hard PI, consistently improves over previous strong baselines for structure-learning on two large-scale tasks.", "desc": "implicitly group closely-related rules instead of explicitly creating a new predicate", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 95, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Understanding the purpose of why sensitive data is used could help improve privacy as well as enable new kinds of access control. In this paper, we introduce a new technique for inferring the purpose of sensitive data usage in the context of Android smartphone apps. We extract multiple kinds of features from decompiled code, focusing on app-specific features and text-based features. These features are then used to train a machine learning classifier. We have evaluated our approach in the context of two sensitive permissions, namely ACCESS_FINE_LOCATION and READ_CONTACT_LIST, and achieved an accuracy of about 85% and 94% respectively in inferring purposes. We have also found that text-based features alone are highly effective in inferring purposes.", "desc": "infer the purpose of why sensitive data is used", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 96, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "In this paper, we focus on automatically detecting events in unconstrained videos without the use of any visual training exemplars. In principle, zero-shot learning makes it possible to train an event detection model based on the assumption that events (e.g. \\emph{birthday party}) can be described by multiple mid-level semantic concepts (e.g. \"blowing candle\", \"birthday cake\"). Towards this goal, we first pre-train a bundle of concept classifiers using data from other sources. Then we evaluate the semantic correlation of each concept \\wrt the event of interest and pick up the relevant concept classifiers, which are applied on all test videos to get multiple prediction score vectors. While most existing systems combine the predictions of the concept classifiers with fixed weights, we propose to learn the optimal weights of the concept classifiers for each testing video by exploring a set of online available videos with free-form text descriptions of their content. To validate the effectiveness of the proposed approach, we have conducted extensive experiments on the latest TRECVID MEDTest 2014, MEDTest 2013 and CCV dataset. The experimental results confirm the superiority of the proposed approach.", "desc": "learn the optimal weights of the concept classifiers for each testing video from free-form text descriptions", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 97, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "In particular for 'low resource' Keyword Search (KWS) and Speech-to-Text (STT) tasks, more untranscribed test data may be available than training data. Several approaches have been proposed to make this data useful during system development, even when initial systems have Word Error Rates (WER) above 70%. In this paper, we present a set of experiments on low-resource languages in telephony speech quality in Assamese, Bengali, Lao, Haitian, Zulu, and Tamil, demonstrating the impact that such techniques can have, in particular learning robust bottle-neck features on the test data. In the case of Tamil, when significantly more test data than training data is available, we integrated semi-supervised training and speaker adaptation on the test data, and achieved significant additional improvements in STT and KWS.", "desc": "make untranscribed test data useful during system development when informaiton has high error rates", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 98, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Building an intelligent agent that simulates human learning of math and science could potentially benefit both cognitive science, by contributing to the understanding of human learning, and artificial intelligence, by advancing the goal of creating human-level intelligence. However, constructing such a learning agent currently requires manual encoding of prior domain knowledge; in addition to being a poor model of human acquisition of prior knowledge, manual knowledge-encoding is both time-consuming and error-prone. Previous research has shown that one of the key factors that differentiates experts and novices is their different representations of knowledge. Experts view the world in terms of deep functional features, while novices view it in terms of shallow perceptual features. Moreover, since the performance of learning algorithms is sensitive to representation, the deep features are also important in achieving effective machine learning. In this paper, we present an efficient algorithm that acquires representation knowledge in the form of \u2030\u0170\u010edeep features\u2030\u0170\u0165, and demonstrate its effectiveness in the domain of algebra as well as synthetic domains. We integrate this algorithm into a machine-learning agent, SimStudent, which learns procedural knowledge by observing a tutor solve sample problems, and by getting feedback while actively solving problems on its own. We show that learning \u2030\u0170\u010edeep features\u2030\u0170\u0165 reduces the requirements for knowledge engineering. Moreover, we propose an approach that automatically discovers student models using the extended SimStudent. By fitting the discovered model to real student learning curve data, we show that it is a better student model than human-generated models, and demonstrate how the discovered model may be used to improve a tutoring system's instructional strategy.", "desc": "avoid manual encoding of prior domain knowledge", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 99, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "This paper describes GenProg, an automated method for repairing defects in off-the-shelf, legacy programs without formal specifications, program annotations, or special coding practices. GenProg uses an extended form of genetic programming to evolve a program variant that retains required functionality but is not susceptible to a given defect, using existing test suites to encode both the defect and required functionality. Structural differencing algorithms and delta debugging reduce the difference between this variant and the original program to a minimal repair. We describe the algorithm and report experimental results of its success on 16 programs totaling 1.25 M lines of C code and 120K lines of module code, spanning eight classes of defects, in 357 seconds, on average. We analyze the generated repairs qualitatively and quantitatively to demonstrate that the process efficiently produces evolved programs that repair the defect, are not fragile input memorizations, and do not lead to serious degradation in functionality.", "desc": "minimize repair section", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 100, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Multimedia event detection (MED) and multimedia event recounting (MER) are fundamental tasks in managing large amounts of unconstrained web videos, and have attracted a lot of attention in recent years. Most existing systems perform MER as a post-processing step on top of the MED results. In order to leverage the mutual benefits of the two tasks, we propose a joint framework that simultaneously detects high-level events and localizes the indicative concepts of the events. Our premise is that a good recounting algorithm should not only explain the detection result, but should also be able to assist detection in the first place. Coupled in a joint optimization framework, recounting improves detection by pruning irrelevant noisy concepts while detection directs recounting to the most discriminative evidences. To better utilize the powerful and interpretable semantic video representation, we segment each video into several shots and exploit the rich temporal structures at shot level. The consequent computational challenge is carefully addressed through a significant improvement of the current ADMM algorithm, which, after eliminating all inner loops and equipping novel closed-form solutions for all intermediate steps, enables us to efficiently process extremely large video corpora. We test the proposed method on the large scale TRECVID MEDTest 2014 and MEDTest 2013 datasets, and obtain very promising results for both MED and MER.", "desc": "detect high-level events and localize the indicative concepts of the events", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 101, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "large-scale idea generation platforms often expose ideators to previous ideas. However, research suggests people generate better ideas if they see abstracted solution paths (e.g., descriptions of solution approaches generated through human sensemaking) rather than being inundated with all prior ideas. Automated and semi-automated methods can also offer interpretations of earlier ideas. To benefit from sensemaking in practice with limited resources, ideation platform developers need to weigh the cost-quality tradeoffs of different methods for surfacing solution paths. To explore this, we conducted an online study where 245 participants generated ideas for two problems in one of five conditions: 1) no stimuli, 2) exposure to all prior ideas, or solution paths extracted from prior ideas using 3) a fully automated workflow, 4) a hybrid human-machine approach, and 5) a fully manual approach. Contrary to expectations, human-generated paths did not improve ideation (as meas- ured by fluency and breadth of ideation) over simply showing all ideas. Machine-generated paths sometimes significantly improved fluency and breadth of ideation over no ideas (although at some cost to idea quality). These findings suggest that automated sensemaking can improve idea generation, but we need more research to understand the value of human sensemaking for crowd ideation.", "desc": "generate better ideas when ideators see abstracted solution paths rather than being inundated with all prior ideas", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 102, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "One important challenge for probabilistic logics is reasoning with very large knowledge bases (KBs) of imperfect information, such as those produced by modern web-scale information extraction systems. One scalability problem shared by many probabilistic logics is that answering queries involves \u2030\u0170\u010egrounding\u2030\u0170\u0165 the query\u2030\u0170\u00d3i.e., mapping it to a propositional representation\u2030\u0170\u00d3and the size of a \u2030\u0170\u010egrounding\u2030\u0170\u0165 grows with database size. To address this bottleneck, we present a first-order probabilistic language called ProPPR in which approximate \u2030\u0170\u010elocal groundings\u2030\u0170\u0165 can be constructed in time independent of database size. Technically, ProPPR is an extension to stochastic logic programs that is biased towards short derivations; it is also closely related to an earlier relational learning algorithm called the path ranking algorithm. We show that the problem of constructing proofs for this logic is related to computation of personalized PageRank on a linearized version of the proof space, and based on this connection, we develop a provably-correct approximate grounding scheme, based on the PageRank\u2030\u0170\u0147Nibble algorithm. Building on this, we develop a fast and easily-parallelized weight-learning algorithm for ProPPR. In our experiments, we show that learning for ProPPR is orders of magnitude faster than learning for Markov logic networks; that allowing mutual recursion (joint learning) in KB inference leads to improvements in performance; and that ProPPR can learn weights for a mutually recursive program with hundreds of clauses defining scores of interrelated predicates over a KB containing one million entities.", "desc": "map the querie of a knowledge base to a propositional representation", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 103, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "The performance of automatic speech recognition (ASR) has improved tremendously due to the application of deep neu- ral networks (DNNs). Despite this progress, building a new ASR system remains a challenging task, requiring various resources, multiple training stages and significant expertise. This paper presents our Eesen framework which drastically simplifies the existing pipeline to build state-of-the-art ASR systems. Acoustic modeling in Eesen involves learning a single recurrent neural network (RNN) predicting context- independent targets (phonemes or characters). To remove the need for pre-generated frame labels, we adopt the connectionist temporal classification (CTC) objective function to infer the alignments between speech and label sequences. A distinctive feature of Eesen is a generalized decoding approach based on weighted finite-state transducers (WFSTs), which enables the efficient incorporation of lexicons and language models into CTC decoding. Experiments show that compared with the standard hybrid DNN systems, Eesen achieves comparable word error rates (WERs), while at the same time speeding up decoding significantly.", "desc": "remove the need for pre-generated frame labels", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 104, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Automatic real-time captioning provides immediate and on demand access to spoken content in lectures or talks, and is a crucial accommodation for deaf and hard of hearing (DHH) people. However, in the presence of specialized content, like in technical talks, automatic speech recognition (ASR) still makes mistakes which may render the output incomprehensible. In this paper, we introduce a new approach, which allows audience or crowd workers, to quickly correct errors that they spot in ASR output. Prior approaches required the crowd worker to manually \u2030\u0170\u010eedit\u2030\u0170\u0165 the ASR hypothesis by selecting and replacing the text, which is not suitable for real-time scenarios. Our approach is faster and allows the worker to simply type corrections for misrecognized words as soon as he or she spots them. The system then finds the most likely position for the correction in the ASR output using keyword search (KWS) and stitches the word into the ASR output. Our work demonstrates the potential of computation to incorporate human input quickly enough to be usable in real-time scenarios, and may be a better method for providing this vital accommodation to DHH people.", "desc": "integrate corrections to software", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 105, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "History event related knowledge is precious and imagery is a powerful medium that records diverse information about the event. In this paper, we propose to automatically construct an image profile given a one sentence description of the historic event which contains where, when, who and what elements. Such a simple input requirement makes our solution easy to scale up and support a wide range of culture preservation and curation related applications ranging from wikipedia enrichment to history education. However, history relevant information on the web is available as \"wild and dirty\" data, which is quite different from clean, manually curated and structured information sources. There are two major challenges to build our proposed image profiles: 1) unconstrained image genre diversity. We categorize images into genres of documents/maps, paintings or photos. Image genre classification involves a full-spectrum of features from low-level color to high-level semantic concepts. 2) image content diversity. It can include faces, objects and scenes. Furthermore, even within the same event, the views and subjects of images are diverse and correspond to different facets of the event. To solve this challenge, we group images at two levels of granularity: iconic image grouping and facet image grouping. These require different types of features and analysis from near exact matching to soft semantic similarity. We develop a full-range feature analysis module which is composed of several levels, each suitable for different types of image analysis tasks. The wide range of features are based on both classical hand-crafted features and different layers of a convolutional neural network. We compare and study the performance of the different levels in the full-range features and show their effectiveness on handling such a wild, unconstrained dataset.", "desc": "manage image content diversity", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 106, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "We propose two well-motivated ranking-based methods to enhance the performance of current state-of-the-art human activity recognition systems. First, as an improvement over the classic power normalization method, we propose a parameter-free ranking technique called rank normalization (RaN). RaN normalizes each dimension of the video features to address the sparse and bursty distribution problems of Fisher Vectors and VLAD. Second, inspired by curriculum learning, we introduce a training-free re-ranking technique called multi-class iterative re-ranking (MIR). MIR captures relationships among action classes by separating easy and typical videos from difficult ones and re-ranking the prediction scores of classifiers accordingly. We demonstrate that our methods significantly improve the performance of state-of-the-art motion features on six real-world datasets.", "desc": "separating easy and typical videos from difficult ones", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 107, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Multimedia event detection has been one of the major endeavors in video event analysis. A variety of approaches have been proposed recently to tackle this problem. Among others, using semantic representation has been accredited for its promising performance and desirable ability for human-understandable reasoning. To generate semantic representation, we usually utilize several external image/video archives and apply the concept detectors trained on them to the event videos. Due to the intrinsic difference of these archives, the resulted representation is presumable to have different predicting capabilities for a certain event. Notwithstanding, not much work is available for assessing the efficacy of semantic representation from the source-level. On the other hand, it is plausible to perceive that some concepts are noisy for detecting a specific event. Motivated by these two shortcomings, we propose a bi-level semantic representation analyzing method. Regarding source-level, our method learns weights of semantic representation attained from different multimedia archives. Meanwhile, it restrains the negative influence of noisy or irrelevant concepts in the overall concept-level. In addition, we particularly focus on efficient multimedia event detection with few positive examples, which is highly appreciated in the real-world scenario. We perform extensive experiments on the challenging TRECVID MED 2013 and 2014 datasets with encouraging results that validate the efficacy of our proposed approach.", "desc": "eliminate noise for detecting a specific event", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}, {"model": "wordclouds.problem", "pk": 108, "fields": {"turk_id": "sam", "paper_id": null, "abstract": "Studying characters plays a vital role in computationally representing and interpreting narratives. Unlike previous work, which has focused on inferring character roles, we focus on the problem of modeling their relationships. Rather than assuming a fixed relationship for a character pair, we hypothesize that relationships temporally evolve with the progress of the narrative, and formulate the problem of relationship modeling as a structured prediction problem. We propose a semi-supervised framework to learn relationship sequences from fully as well as partially labeled data. We present a Markovian model capable of accumulating historical beliefs about the relationship and status changes. We  use a set of rich linguistic and semantically motivated features that incorporate world knowledge to investigate the textual content of narrative. We empirically demonstrate that such a framework outperforms competitive baselines.", "desc": "understand temporal relationships between characters in a narrative", "user": null, "trial": null, "type": "ok", "submit_date": "2016-07-19T12:08:45Z"}}]
